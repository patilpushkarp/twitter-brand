{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import spacy\n",
    "import swifter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('./../../code/data/starbucks/data.h5', key='starbucks')\n",
    "df = df.iloc[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates('tweet', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset='tweet', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3977, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['username'].isin(['starbucks_es', 'starbucks_cstm', 'starbucks_j_cpg', 'starbuckspoho', \n",
    "                                'starbuckspoho', 'starbuckshomeme', 'starbucksperu'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3313, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(text):\n",
    "    \"\"\"Method to perform preprocessing of tweets\"\"\"\n",
    "    text = str(text).lower() # Convert tweets to lower case\n",
    "    text = re.sub(r'@ *\\w*', '', str(text)) # Remove tagged usernames from the tweets\n",
    "    text = re.sub(r'#\\w+', '', str(text)) # Remove hashtags from the tweets\n",
    "    text = re.sub('\\n', ' ', str(text)) # Remove newline characters from the tweets\n",
    "    text = re.sub('\\xa0', ' ', str(text)) # Remove special characters coverted to strings from the tweets. In this case it is \"\\xa0\"\n",
    "    text = re.sub('&amp', ' ', str(text)) # Remove \"&amp\" from the tweets\n",
    "    text = re.sub(r'http\\S+', '', str(text)) # Remove links from the tweets\n",
    "    text = re.sub(r'[^A-Za-z0-9 ]+', '', str(text)) # Keep only alphanumeric characters in the tweets\n",
    "    return text\n",
    "\n",
    "df.loc[:, 'preprocessed_tweet'] = df['tweet'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove blank tweets after preprocessing\n",
    "df = df[df['preprocessed_tweet'].map(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311c525813ef4be19f547e505df0b71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/3313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lemmatization(text):\n",
    "    \"\"\"Function to lemmatized tokenied sentence\"\"\"\n",
    "    return \" \".join([token.lemma_ if token.lemma_ != '-PRON-' else token.lower_ for token in nlp(text)])\n",
    "\n",
    "df['preprocessed_tweet'] = df['preprocessed_tweet'].swifter.apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b3d9474b144e358a3a106b1b03c8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/3313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"Method to remove stopwords from tweet text\"\"\"\n",
    "\n",
    "    stopwords = STOPWORDS.union(set(['starbucks', 'starbuck']))\n",
    "\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords]\n",
    "    return \" \".join(tokens_without_sw)\n",
    "\n",
    "df['preprocessed_tweet'] = df['preprocessed_tweet'].swifter.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>preprocessed_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHY Y’all lie &amp;amp; say Starbucks took EBT now...</td>\n",
       "      <td>y lie ebt pour shii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thanks A Latta Giveaway\\n#WIN a $10 Starbucks ...</td>\n",
       "      <td>thank latta giveaway 10 amazon gc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I used to hate Starbucks but now I love it so ...</td>\n",
       "      <td>use hate love want invent new frappuccino flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>philz needs to replace the starbucks on story ...</td>\n",
       "      <td>philz need replace story white fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@staceyabrams @BeeForGeorgia There were more p...</td>\n",
       "      <td>people grand opening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>Hey @Starbucks I think I maybe the only one in...</td>\n",
       "      <td>hey think maybe cinnamon dolce syrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>1h30 walk done !! now im resting in a mall wit...</td>\n",
       "      <td>1h30 walk rest mall ice americano fast 1h30 wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>@VP  you know I am working this corner to get ...</td>\n",
       "      <td>know work corner money coffee tuesday election...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>Starting soon! Register here to hear from youn...</td>\n",
       "      <td>start soon register hear young striker unionis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>@Clodia55680147 you’re the one who literally a...</td>\n",
       "      <td>literally ask know american coffees taste like...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3313 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  \\\n",
       "0     WHY Y’all lie &amp; say Starbucks took EBT now...   \n",
       "1     Thanks A Latta Giveaway\\n#WIN a $10 Starbucks ...   \n",
       "2     I used to hate Starbucks but now I love it so ...   \n",
       "3     philz needs to replace the starbucks on story ...   \n",
       "4     @staceyabrams @BeeForGeorgia There were more p...   \n",
       "...                                                 ...   \n",
       "3994  Hey @Starbucks I think I maybe the only one in...   \n",
       "3995  1h30 walk done !! now im resting in a mall wit...   \n",
       "3996  @VP  you know I am working this corner to get ...   \n",
       "3997  Starting soon! Register here to hear from youn...   \n",
       "3998  @Clodia55680147 you’re the one who literally a...   \n",
       "\n",
       "                                     preprocessed_tweet  \n",
       "0                                   y lie ebt pour shii  \n",
       "1                     thank latta giveaway 10 amazon gc  \n",
       "2      use hate love want invent new frappuccino flavor  \n",
       "3                     philz need replace story white fr  \n",
       "4                                  people grand opening  \n",
       "...                                                 ...  \n",
       "3994               hey think maybe cinnamon dolce syrup  \n",
       "3995  1h30 walk rest mall ice americano fast 1h30 wa...  \n",
       "3996  know work corner money coffee tuesday election...  \n",
       "3997  start soon register hear young striker unionis...  \n",
       "3998  literally ask know american coffees taste like...  \n",
       "\n",
       "[3313 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tweet', 'preprocessed_tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zl/bqtzmz3s0xl5_ddgbjsqxsww0000gn/T/ipykernel_80764/609922302.py:1: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['Unnamed: 0', 'tweet', 'conversation_id', 'date', 'hashtags',\n",
      "       'inReplyToTweetId', 'reply_to', 'language', 'likes_count', 'media',\n",
      "       'mentions', 'quoted_tweet', 'retweets_count', 'link',\n",
      "       'user_status_count', 'location', 'name', 'description', 'verified',\n",
      "       'url', 'user_id', 'username', 'preprocessed_tweet'],\n",
      "      dtype='object')]\n",
      "\n",
      "  df.to_hdf('./../../code/data/starbucks/data.h5', key='preprocessed_starbucks')\n"
     ]
    }
   ],
   "source": [
    "df.to_hdf('./../../code/data/starbucks/data.h5', key='preprocessed_starbucks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af77eb27f514ee114388f6898d9553454263f7eea260918546d16a8e581c8922"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
